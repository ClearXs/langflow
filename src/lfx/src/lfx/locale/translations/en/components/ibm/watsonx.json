{
  "description": "Generate text using IBM watsonx.ai foundation models.",
  "url": {
    "display_name": "watsonx API Endpoint",
    "info": "The base URL of the API."
  },
  "project_id": {
    "display_name": "watsonx Project ID",
    "info": "The project ID or deployment space ID that is associated with the foundation model."
  },
  "api_key": {
    "display_name": "Watsonx API Key",
    "info": "The API Key to use for the model."
  },
  "model_name": {
    "display_name": "Model Name"
  },
  "max_tokens": {
    "display_name": "Max Tokens",
    "info": "The maximum number of tokens to generate."
  },
  "stop_sequence": {
    "display_name": "Stop Sequence",
    "info": "Sequence where generation should stop."
  },
  "temperature": {
    "display_name": "Temperature",
    "info": "Controls randomness, higher values increase diversity."
  },
  "top_p": {
    "display_name": "Top P",
    "info": "The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus."
  },
  "frequency_penalty": {
    "display_name": "Frequency Penalty",
    "info": "Penalty for frequency of token usage."
  },
  "presence_penalty": {
    "display_name": "Presence Penalty",
    "info": "Penalty for token presence in prior text."
  },
  "seed": {
    "display_name": "Random Seed",
    "info": "The random seed for the model."
  },
  "logprobs": {
    "display_name": "Log Probabilities",
    "info": "Whether to return log probabilities of the output tokens."
  },
  "top_logprobs": {
    "display_name": "Top Log Probabilities",
    "info": "Number of most likely tokens to return at each position."
  },
  "logit_bias": {
    "display_name": "Logit Bias",
    "info": "JSON string of token IDs to bias or suppress (e.g., {\"1003\": -100, \"1004\": 100})."
  },
  "errors": {
    "fetch_failed": "Error fetching models: {error}. Using default models.",
    "config_update_failed": "Error updating model options: {error}",
    "invalid_logit_bias": "Invalid logit_bias JSON format: {error}. Using default instead."
  },
  "logs": {
    "fetching_models": "Fetching available models from watsonx.ai - Base URL: {base_url}",
    "requesting_models": "Requesting models from endpoint: {endpoint}",
    "models_fetched": "Successfully fetched {count} model(s)",
    "using_default_models": "Using default models: {count} model(s)",
    "updating_config": "Updating build config - Field: {field}, Value: {value}",
    "fetching_models_for_url": "Fetching models for URL: {url}",
    "models_updated": "Updated model options: {count} model(s) found in {url}",
    "building_model": "Building watsonx.ai model - Model: {model}, URL: {url}",
    "parsing_logit_bias": "Parsing logit_bias JSON",
    "logit_bias_parsed": "Logit bias parsed successfully: {bias}",
    "using_default_logit_bias": "Using default logit_bias",
    "configuring_parameters": "Configuring chat parameters - Max tokens: {max_tokens}, Temperature: {temperature}, Top P: {top_p}, Streaming: {streaming}",
    "creating_chat_instance": "Creating ChatWatsonx instance",
    "model_built": "watsonx.ai model built successfully"
  }
}