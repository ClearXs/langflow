{
  "display_name": "Ollama",
  "description": "Generate text using Ollama Local LLMs.",
  "base_url": {
    "display_name": "Base URL",
    "info": "Endpoint of the Ollama API."
  },
  "model_name": {
    "display_name": "Model Name",
    "info": "Refer to https://ollama.com/library for more models."
  },
  "temperature": {
    "display_name": "Temperature"
  },
  "format": {
    "display_name": "Format",
    "info": "Specify the format of the output (e.g., json)."
  },
  "metadata": {
    "display_name": "Metadata",
    "info": "Metadata to add to the run trace."
  },
  "mirostat": {
    "display_name": "Mirostat",
    "info": "Enable/disable Mirostat sampling for controlling perplexity."
  },
  "mirostat_eta": {
    "display_name": "Mirostat Eta",
    "info": "Learning rate for Mirostat algorithm. (Default: 0.1)"
  },
  "mirostat_tau": {
    "display_name": "Mirostat Tau",
    "info": "Controls the balance between coherence and diversity of the output. (Default: 5.0)"
  },
  "num_ctx": {
    "display_name": "Context Window Size",
    "info": "Size of the context window for generating tokens. (Default: 2048)"
  },
  "num_gpu": {
    "display_name": "Number of GPUs",
    "info": "Number of GPUs to use for computation. (Default: 1 on macOS, 0 to disable)"
  },
  "num_thread": {
    "display_name": "Number of Threads",
    "info": "Number of threads to use during computation. (Default: detected for optimal performance)"
  },
  "repeat_last_n": {
    "display_name": "Repeat Last N",
    "info": "How far back the model looks to prevent repetition. (Default: 64, 0 = disabled, -1 = num_ctx)"
  },
  "repeat_penalty": {
    "display_name": "Repeat Penalty",
    "info": "Penalty for repetitions in generated text. (Default: 1.1)"
  },
  "tfs_z": {
    "display_name": "TFS Z",
    "info": "Tail free sampling value. (Default: 1)"
  },
  "timeout": {
    "display_name": "Timeout",
    "info": "Timeout for the request stream."
  },
  "top_k": {
    "display_name": "Top K",
    "info": "Limits token selection to top K. (Default: 40)"
  },
  "top_p": {
    "display_name": "Top P",
    "info": "Works together with top-k. (Default: 0.9)"
  },
  "verbose": {
    "display_name": "Verbose",
    "info": "Whether to print out response text."
  },
  "tags": {
    "display_name": "Tags",
    "info": "Comma-separated list of tags to add to the run trace."
  },
  "stop_tokens": {
    "display_name": "Stop Tokens",
    "info": "Comma-separated list of tokens to signal the model to stop generating text."
  },
  "system": {
    "display_name": "System",
    "info": "System to use for generating text."
  },
  "tool_model_enabled": {
    "display_name": "Tool Model Enabled",
    "info": "Whether to enable tool calling in the model."
  },
  "template": {
    "display_name": "Template",
    "info": "Template to use for generating text."
  }
}